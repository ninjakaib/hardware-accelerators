{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Designing Floating Point Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Type\n",
    "import pyrtl\n",
    "from pyrtl import *\n",
    "import numpy as np\n",
    "from enum import IntEnum\n",
    "from hardware_accelerators.dtypes import BaseFloat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x: WireVector):\n",
    "    return pyrtl.select(x[-1], 0, x)\n",
    "\n",
    "\n",
    "def sigmoid(x: WireVector):\n",
    "    pass\n",
    "\n",
    "\n",
    "# Just an example\n",
    "class ActivationFunction(IntEnum):\n",
    "    RELU = 0\n",
    "    SIGMOID = 1\n",
    "    TANH = 2\n",
    "    SOFTMAX = 3\n",
    "\n",
    "\n",
    "class ActivationUnit:\n",
    "    def __init__(self, size: int, dtype: Type[BaseFloat], activation_functions: list):\n",
    "        self.size = size\n",
    "        self.dtype = dtype\n",
    "        self.activation_functions = activation_functions\n",
    "\n",
    "        self.activation_select = WireVector(len(activation_functions).bit_length())\n",
    "        self.data_ins = [WireVector(dtype.bitwidth()) for _ in range(size)]\n",
    "        self.outputs = [WireVector(dtype.bitwidth()) for _ in range(size)]\n",
    "\n",
    "        for input, output in zip(self.data_ins, self.outputs):\n",
    "            with conditional_assignment:\n",
    "                with self.activation_select == ActivationFunction.RELU:\n",
    "                    output |= relu(input)\n",
    "                with self.activation_select == ActivationFunction.SIGMOID:\n",
    "                    output |= sigmoid(input)\n",
    "                with self.activation_select == ActivationFunction.TANH:\n",
    "                    output |= tanh(input)\n",
    "                with self.activation_select == ActivationFunction.SOFTMAX:\n",
    "                    output |= softmax(input)\n",
    "                with otherwise:\n",
    "                    output |= input\n",
    "\n",
    "    def connect_inputs(\n",
    "        self, data_ins: list | None = None, activation_select: WireVector | None = None\n",
    "    ):\n",
    "        if data_ins is not None:\n",
    "            assert len(data_ins) == self.size\n",
    "            for i in range(self.size):\n",
    "                self.data_ins[i] <<= data_ins[i]\n",
    "        if activation_select is not None:\n",
    "            assert (\n",
    "                activation_select.bitwidth\n",
    "                == len(self.activation_functions).bit_length()\n",
    "            )\n",
    "            self.activation_select <<= activation_select"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
