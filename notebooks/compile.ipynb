{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pyrtl\n",
    "from pyrtl import WireVector, Input, Output, CompiledSimulation, reset_working_block\n",
    "import torch\n",
    "from typing import Literal\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from hardware_accelerators.dtypes import *\n",
    "from hardware_accelerators.simulation.compile import (\n",
    "    ReusableCompiledSimulation,\n",
    "    CompiledAccelerator,\n",
    ")\n",
    "from hardware_accelerators.simulation.accelerator import CompiledAcceleratorSimulator\n",
    "from hardware_accelerators.rtllib.accelerator import CompiledAcceleratorConfig\n",
    "from hardware_accelerators.rtllib.multipliers import (\n",
    "    float_multiplier,\n",
    "    float_multiplier_simple,\n",
    ")\n",
    "from hardware_accelerators.nn import load_model, MLP\n",
    "\n",
    "model = load_model(\"models/mlp_mnist.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_w8a32 = CompiledAcceleratorConfig(\n",
    "    array_size=2,\n",
    "    activation_type=Float32,\n",
    "    weight_type=Float8,\n",
    "    multiplier=float_multiplier,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing adders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyrtl.rtllib.adders import carrysave_adder, cla_adder, kogge_stone, ripple_add\n",
    "from pyrtl.rtllib.libutils import twos_comp_repr, rev_twos_comp_repr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_wire(sim, wire, two_comp=False):\n",
    "    bits = len(wire)\n",
    "    raw = sim.inspect(wire)\n",
    "    val = rev_twos_comp_repr(raw, bits) if two_comp else raw\n",
    "    print(f\"{wire.name} ({bits} bits) = {val}, 0b{format(raw, f'0{bits}b')}\")\n",
    "\n",
    "\n",
    "def analyze():\n",
    "    pyrtl.synthesize()\n",
    "    pyrtl.optimize()\n",
    "    timing = pyrtl.TimingAnalysis()\n",
    "    delay = timing.max_length()\n",
    "    print(f\"\\nest. max delay: {delay:.2f} ps\")\n",
    "    print(f\"est. max freq: {timing.max_freq():.2f} MHz\")\n",
    "    print(f\"est. area: {pyrtl.area_estimation()}\\n\\n\")\n",
    "\n",
    "\n",
    "pyrtl.set_debug_mode(False)\n",
    "\n",
    "dtype = BF16\n",
    "e_bits = dtype.exponent_bits()\n",
    "bias = dtype.bias()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_working_block()\n",
    "exp_a = pyrtl.Input(e_bits, \"exp_a\")  # type: ignore\n",
    "exp_b = pyrtl.Input(e_bits, \"exp_b\")  # type: ignore\n",
    "exp_diff = pyrtl.Output(e_bits + 1, \"exp_diff\")  # type: ignore\n",
    "exp_diff <<= exp_a - exp_b\n",
    "pyrtl.output_to_verilog(open(\"simple_sub.v\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_a (8 bits) = 10, 0b00001010\n",
      "exp_b (8 bits) = 40, 0b00101000\n",
      "exp_diff (9 bits) = -30, 0b111100010\n",
      "signed_shift (9 bits) = 286, 0b100011110\n",
      "abs_shift (8 bits) = 30, 0b00011110\n",
      "exp_larger (8 bits) = 40, 0b00101000\n",
      "\n",
      "est. max delay: 2773.60 ps\n",
      "est. max freq: 316.80 MHz\n",
      "est. area: (0.000975744, 0)\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "PyrtlError",
     "evalue": "Input \"tmp256151\" has no input value specified",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPyrtlError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[408], line 60\u001b[0m\n\u001b[1;32m     53\u001b[0m abs_shift \u001b[38;5;241m<<\u001b[39m\u001b[38;5;241m=\u001b[39m pyrtl\u001b[38;5;241m.\u001b[39mselect(\n\u001b[1;32m     54\u001b[0m     is_neg,\n\u001b[1;32m     55\u001b[0m     pyrtl\u001b[38;5;241m.\u001b[39mconcat(exp_diff[e_bits], (\u001b[38;5;241m~\u001b[39mexp_diff[:e_bits] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)[:e_bits]),\n\u001b[1;32m     56\u001b[0m     exp_diff[:e_bits],\n\u001b[1;32m     57\u001b[0m )\n\u001b[1;32m     59\u001b[0m fast_sim \u001b[38;5;241m=\u001b[39m pyrtl\u001b[38;5;241m.\u001b[39mSimulation(tracer\u001b[38;5;241m=\u001b[39mpyrtl\u001b[38;5;241m.\u001b[39mSimulationTrace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m), block\u001b[38;5;241m=\u001b[39mfast_block)\n\u001b[0;32m---> 60\u001b[0m \u001b[43mfast_sim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[43mexp_a\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexp_b\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# neg_b.name = \"neg_b\"\u001b[39;00m\n\u001b[1;32m     64\u001b[0m exp_diff\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexp_diff_twos\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/dsc180/lib/python3.12/site-packages/pyrtl/simulation.py:241\u001b[0m, in \u001b[0;36mSimulation.step\u001b[0;34m(self, provided_inputs)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_set \u001b[38;5;241m!=\u001b[39m supplied_inputs:\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m input_set\u001b[38;5;241m.\u001b[39mdifference(supplied_inputs):\n\u001b[0;32m--> 241\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m PyrtlError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m has no input value specified\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m i\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregvalue)  \u001b[38;5;66;03m# apply register updates from previous step\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m net \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mordered_nets:\n",
      "\u001b[0;31mPyrtlError\u001b[0m: Input \"tmp256151\" has no input value specified"
     ]
    }
   ],
   "source": [
    "reset_working_block()\n",
    "\n",
    "slow_block = pyrtl.Block()\n",
    "\n",
    "A = 10\n",
    "B = 40\n",
    "# A = 60\n",
    "# B = 40\n",
    "\n",
    "with pyrtl.set_working_block(slow_block):\n",
    "    exp_a = pyrtl.Input(e_bits, \"exp_a\")  # type: ignore\n",
    "    exp_b = pyrtl.Input(e_bits, \"exp_b\")  # type: ignore\n",
    "    exp_diff = pyrtl.WireVector(e_bits + 1, \"exp_diff\")  # type: ignore\n",
    "    signed_shift = WireVector(e_bits + 1, \"signed_shift\")  # type: ignore\n",
    "    exp_larger = WireVector(e_bits, \"exp_larger\")  # type: ignore\n",
    "    abs_shift = Output(e_bits, \"abs_shift\")  # type: ignore\n",
    "\n",
    "    exp_diff <<= exp_a - exp_b  # This can be negative, indicating which is larger\n",
    "    exp_larger <<= pyrtl.mux(exp_diff[e_bits], exp_a, exp_b)\n",
    "    signed_shift <<= pyrtl.mux(\n",
    "        exp_diff[e_bits],\n",
    "        exp_diff[:e_bits],\n",
    "        pyrtl.concat(exp_diff[e_bits], (~exp_diff[:e_bits] + 1)[:e_bits]),\n",
    "    )\n",
    "    abs_shift <<= signed_shift[:e_bits]\n",
    "\n",
    "    slow_sim = pyrtl.Simulation(\n",
    "        tracer=pyrtl.SimulationTrace(\"all\")\n",
    "    )  # , block=slow_block)\n",
    "    slow_sim.step({exp_a: A, exp_b: B})  # type: ignore\n",
    "\n",
    "    inspect_wire(slow_sim, exp_a)\n",
    "    inspect_wire(slow_sim, exp_b)\n",
    "    inspect_wire(slow_sim, exp_diff, True)\n",
    "    inspect_wire(slow_sim, signed_shift)\n",
    "    inspect_wire(slow_sim, abs_shift)\n",
    "    inspect_wire(slow_sim, exp_larger)\n",
    "    analyze()\n",
    "\n",
    "fast_block = pyrtl.Block()\n",
    "\n",
    "with pyrtl.set_working_block(fast_block):\n",
    "    exp_a = pyrtl.Input(e_bits, \"exp_a\")  # type: ignore\n",
    "    exp_b = pyrtl.Input(e_bits, \"exp_b\")  # type: ignore\n",
    "    exp_diff = pyrtl.WireVector(e_bits + 1, \"exp_diff\")  # type: ignore\n",
    "    abs_shift = Output(e_bits, \"abs_shift\")  # type: ignore\n",
    "\n",
    "    neg_b = (~exp_b + 1)[:e_bits]\n",
    "    exp_diff <<= carrysave_adder(exp_a, ~exp_b, pyrtl.Const(1), final_adder=kogge_stone)\n",
    "\n",
    "    is_neg = ~exp_diff[e_bits]\n",
    "\n",
    "    abs_shift <<= pyrtl.select(\n",
    "        is_neg,\n",
    "        pyrtl.concat(exp_diff[e_bits], (~exp_diff[:e_bits] + 1)[:e_bits]),\n",
    "        exp_diff[:e_bits],\n",
    "    )\n",
    "\n",
    "    fast_sim = pyrtl.Simulation(tracer=pyrtl.SimulationTrace(\"all\"), block=fast_block)\n",
    "    fast_sim.step({exp_a: A, exp_b: B})  # type: ignore\n",
    "\n",
    "    # neg_b.name = \"neg_b\"\n",
    "    exp_diff.name = \"exp_diff_twos\"\n",
    "    is_neg.name = \"is_neg\"\n",
    "\n",
    "    # inspect_wire(fast_sim, neg_b, True)\n",
    "    inspect_wire(fast_sim, exp_diff)\n",
    "    inspect_wire(fast_sim, is_neg)\n",
    "    inspect_wire(\n",
    "        fast_sim,\n",
    "        abs_shift,\n",
    "    )\n",
    "\n",
    "    analyze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing signed_add with bitwidth 16\n",
      "addition bitwidth:  17\n",
      "The total block timing delay is  4870.070000000002\n",
      "est. max frequency:  190.36487235083476\n",
      "est. area: (0.00121968, 0)\n",
      "\n",
      "\n",
      "Analyzing cla_adder with bitwidth 16\n",
      "addition bitwidth:  17\n",
      "The total block timing delay is  1900.5399999999997\n",
      "est. max frequency:  437.91656813543887\n",
      "est. area: (0.00117612, 0)\n",
      "\n",
      "\n",
      "Analyzing kogge_stone with bitwidth 16\n",
      "addition bitwidth:  17\n",
      "The total block timing delay is  986.8399999999999\n",
      "est. max frequency:  730.0122642060387\n",
      "est. area: (0.00182952, 0)\n",
      "\n",
      "\n",
      "Analyzing ripple_add with bitwidth 16\n",
      "addition bitwidth:  17\n",
      "The total block timing delay is  4735.000000000003\n",
      "est. max frequency:  195.38882375928085\n",
      "est. area: (0.001202256, 0)\n",
      "\n",
      "\n",
      "Analyzing <lambda> with bitwidth 16\n",
      "using faster multiplier\n",
      "addition bitwidth:  16\n",
      "The total block timing delay is  7632.510000000002\n",
      "est. max frequency:  124.75812518479795\n",
      "est. area: (0.010001376, 0)\n",
      "\n",
      "\n",
      "Analyzing carrysave_adder with bitwidth 16\n",
      "addition bitwidth:  18\n",
      "The total block timing delay is  2202.84\n",
      "est. max frequency:  386.7215295609937\n",
      "est. area: (0.00230868, 0)\n",
      "\n",
      "\n",
      "Analyzing carrysave_adder with bitwidth 16\n",
      "addition bitwidth:  18\n",
      "The total block timing delay is  1289.1399999999999\n",
      "est. max frequency:  598.0360496130708\n",
      "est. area: (0.00296208, 0)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def analyze_adder(adder, bitwidth, **kwargs):\n",
    "    print(f\"Analyzing {adder.__name__} with bitwidth {bitwidth}\")\n",
    "    a, b = pyrtl.Input(bitwidth, \"a\"), pyrtl.Input(bitwidth, \"b\")\n",
    "    out = pyrtl.Output(bitwidth + 1, \"out\")\n",
    "    sum = adder(a, b, **kwargs)\n",
    "    print(\"addition bitwidth: \", len(sum))\n",
    "    out <<= sum\n",
    "    pyrtl.synthesize()\n",
    "    pyrtl.optimize()\n",
    "    timing = pyrtl.TimingAnalysis()\n",
    "    timing.print_max_length()\n",
    "    print(\"est. max frequency: \", timing.max_freq())\n",
    "    print(f\"est. area: {pyrtl.area_estimation()}\\n\\n\")\n",
    "\n",
    "\n",
    "adder_funcs = [\n",
    "    pyrtl.signed_add,\n",
    "    cla_adder,\n",
    "    kogge_stone,\n",
    "    ripple_add,\n",
    "    lambda a, b: float_multiplier(a, b, BF16),\n",
    "]\n",
    "for exp_a in adder_funcs:\n",
    "    reset_working_block()\n",
    "    analyze_adder(exp_a, 16)\n",
    "\n",
    "reset_working_block()\n",
    "analyze_adder(carrysave_adder, 16, c=pyrtl.Input(16, \"c\"), final_adder=cla_adder)\n",
    "reset_working_block()\n",
    "analyze_adder(carrysave_adder, 16, c=pyrtl.Input(16, \"c\"), final_adder=kogge_stone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configs for power, area, delay analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baselines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 4\n",
    "# Baselines\n",
    "config_w8a16 = CompiledAcceleratorConfig(\n",
    "    array_size=SIZE,\n",
    "    activation_type=BF16,\n",
    "    weight_type=Float8,\n",
    "    multiplier=float_multiplier,\n",
    "    pipeline=True,\n",
    ")\n",
    "config_w8a16 = CompiledAcceleratorConfig(\n",
    "    array_size=SIZE,\n",
    "    activation_type=BF16,\n",
    "    weight_type=Float8,\n",
    "    multiplier=float_multiplier,\n",
    "    pipeline=True,\n",
    ")\n",
    "config_w8a32 = CompiledAcceleratorConfig(\n",
    "    array_size=8,\n",
    "    activation_type=Float32,\n",
    "    weight_type=Float8,\n",
    "    multiplier=float_multiplier_simple,\n",
    ")\n",
    "config_w16a16 = CompiledAcceleratorConfig(\n",
    "    array_size=SIZE,\n",
    "    activation_type=BF16,\n",
    "    weight_type=BF16,\n",
    "    multiplier=float_multiplier,\n",
    "    pipeline=True,\n",
    ")\n",
    "config_w16a32 = CompiledAcceleratorConfig(\n",
    "    array_size=SIZE,\n",
    "    activation_type=BF16,\n",
    "    weight_type=BF16,\n",
    "    multiplier=float_multiplier_simple,\n",
    "    pipeline=True,\n",
    ")\n",
    "config_w32a32 = CompiledAcceleratorConfig(\n",
    "    array_size=SIZE,\n",
    "    activation_type=BF16,\n",
    "    weight_type=BF16,\n",
    "    multiplier=float_multiplier_simple,\n",
    "    pipeline=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slow, power efficient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Literal' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_multipliers_for_config\u001b[39m(w_a_dtypes: \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mint\u001b[39m,\u001b[38;5;28mint\u001b[39m], mode\u001b[38;5;241m=\u001b[39m\u001b[43mLiteral\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mefficient\u001b[39m\u001b[38;5;124m\"\u001b[39m, ]):\n\u001b[1;32m      2\u001b[0m     w_dtype, a_dtype \u001b[38;5;241m=\u001b[39m w_a_dtypes\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_configs\u001b[39m():\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Literal' is not defined"
     ]
    }
   ],
   "source": [
    "def _get_multipliers_for_config(\n",
    "    w_a: tuple[int, int],\n",
    "    mode: Literal[\"basic\", \"standard\", \"fast\", \"fastest\"],\n",
    "):\n",
    "    \"\"\"Get the standard and lmul multipliers based on mode, and the weight and activation types.\n",
    "\n",
    "    Basic mode uses no pipelining, simplest internal components. Will be the slowest but also the most power efficient.\n",
    "    Standard mode uses no pipelining, but with faster internal components. Will be slightly faster than basic mode.\n",
    "    Fast mode uses pipelining with simpler internal components. Will be significantly faster than standard mode.\n",
    "    Fastest mode uses pipelining with the fastest internal components. Will be the fastest but also the most power hungry.\n",
    "    \n",
    "    Args:\n",
    "        w_a (tuple[int, int]): The weight and activation types.\n",
    "        mode (Literal[\"basic\", \"standard\", \"fast\", \"fastest\"]): The mode to use.\"\n",
    "        \n",
    "    Returns:\n",
    "        tuple[float_multiplier, l_mul]: The appropriate pair of IEEE standard float multiplier and l-mul implementation.\n",
    "    \"\"\"\n",
    "    mode_map = {\n",
    "        \"basic\": (float_multiplier_simple, lmul_simple),\n",
    "        \"standard\": (float_multiplier, lmul_fast),\n",
    "        \"fast\": (float_multiplier_pipeline, lmul_fast),\n",
    "        \"fastest\": (float_multiplier_pipeline, lmul_fastest),\n",
    "    }\n",
    "    return mode_map.get(mode, (float_multiplier_simple, lmul_simple)\n",
    "    if mode == \"basic\":\n",
    "        efficient_map = { \n",
    "            (8, 8): (float_multiplier_simple, lmul_simple),\n",
    "            (8, 16): (float_multiplier_simple, lmul_8x16),\n",
    "\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "def generate_configs():\n",
    "    w_a_dtypes = [(8, 8), (8, 16), (8, 32), (16, 16), (16, 32), (32, 32)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_w8a8_e = CompiledAcceleratorConfig(\n",
    "    array_size=SIZE,\n",
    "    weight_type=Float8,\n",
    "    activation_type=Float8,\n",
    "    multiplier=float_multiplier_simple,\n",
    "    pipeline=True,\n",
    ")\n",
    "config_w8a16_e = CompiledAcceleratorConfig(\n",
    "    array_size=SIZE,\n",
    "    weight_type=Float8,\n",
    "    activation_type=BF16,\n",
    "    multiplier=float_multiplier_simple,\n",
    "    pipeline=True,\n",
    ")\n",
    "config_w8a16_e = CompiledAcceleratorConfig(\n",
    "    array_size=SIZE,\n",
    "    weight_type=Float8,\n",
    "    activation_type=BF16,\n",
    "    multiplier=float_multiplier_simple,\n",
    "    pipeline=True,\n",
    ")\n",
    "config_w8a32_e = CompiledAcceleratorConfig(\n",
    "    array_size=SIZE,\n",
    "    weight_type=Float8,\n",
    "    activation_type=Float32,\n",
    "    multiplier=float_multiplier_simple,\n",
    ")\n",
    "config_w16a16_e = CompiledAcceleratorConfig(\n",
    "    array_size=SIZE,\n",
    "    weight_type=BF16,\n",
    "    activation_type=BF16,\n",
    "    multiplier=float_multiplier_simple,\n",
    "    pipeline=True,\n",
    ")\n",
    "config_w16a32_e = CompiledAcceleratorConfig(\n",
    "    array_size=SIZE,\n",
    "    weight_type=BF16,\n",
    "    activation_type=BF16,\n",
    "    multiplier=float_multiplier_simple,\n",
    "    pipeline=True,\n",
    ")\n",
    "config_w32a32_e = CompiledAcceleratorConfig(\n",
    "    array_size=SIZE,\n",
    "    weight_type=BF16,\n",
    "    activation_type=BF16,\n",
    "    multiplier=float_multiplier_simple,\n",
    "    pipeline=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test loading from saved sim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data transformation: convert images to tensor and normalize them\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,)),\n",
    "    ]\n",
    ")\n",
    "# Download MNIST test data\n",
    "test_dataset = datasets.MNIST(\n",
    "    root=\"./data\", train=False, download=True, transform=transform\n",
    ")\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "\n",
    "def get_batch(batch_size):\n",
    "    loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    batch, labels = next(iter(loader))\n",
    "    return batch.reshape(batch_size, -1).numpy(), labels.numpy()\n",
    "\n",
    "\n",
    "def get_activation():\n",
    "    image, _ = next(iter(test_loader))\n",
    "    image = image.detach().numpy().reshape(-1)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing compiled sims\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_working_block()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using precompiled library: /Users/kaibreese/UCSD/dsc180b/hardware-accelerators/hardware_accelerators/bin/w8ab16s8/pyrtlsim.so\n",
      "Using precompiled library: /Users/kaibreese/UCSD/dsc180b/hardware-accelerators/hardware_accelerators/bin/wb16ab16s8/pyrtlsim.so\n"
     ]
    }
   ],
   "source": [
    "sim_w8a16 = CompiledAcceleratorSimulator(config_w8a16, model=model)\n",
    "sim_w16a16 = CompiledAcceleratorSimulator(config_w16a16, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyrtl.set_debug_mode(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing hardware for config w8a32-2x2...\n",
      "Saved compiled binary for config w8a32-2x2 to /Users/kaibreese/.hardware_accelerators/sim_cache/77203ff37f1343bf\n"
     ]
    }
   ],
   "source": [
    "reset_working_block()\n",
    "\n",
    "config_w8a32 = CompiledAcceleratorConfig(\n",
    "    array_size=2,\n",
    "    activation_type=Float32,\n",
    "    weight_type=Float8,\n",
    "    multiplier=float_multiplier,\n",
    ")\n",
    "\n",
    "sim_w8a32 = CompiledAcceleratorSimulator(config_w8a32, model=model, recompile=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running batch inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 11266/11438 tiles\n",
      "[7 2 1 0 4 1 4 9 5 9]\n",
      "[7 2 1 0 4 1 4 9 5 9]\n",
      "[ True  True  True  True  True  True  True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "batch, labels = get_batch(10)\n",
    "\n",
    "results = sim_w8a32.predict_batch(batch)\n",
    "preds = np.argmax(results, axis=1)\n",
    "\n",
    "print()\n",
    "print(preds)\n",
    "print(labels)\n",
    "print(preds == labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 10)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = sim_w8a16.predict(get_activation())\n",
    "np.argmax(pred).item(), len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 10)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = sim_w16a16.predict(get_activation())\n",
    "np.argmax(pred).item(), len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1584/1618 tiles\n",
      "[7 2 1 0 4 1 4 9 5 9]\n",
      "[7 2 1 0 4 1 4 9 5 9]\n",
      "[ True  True  True  True  True  True  True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "batch, labels = get_batch(10)\n",
    "\n",
    "results = sim_w8a16.predict_batch(batch)\n",
    "preds = np.argmax(results, axis=1)\n",
    "\n",
    "print()\n",
    "print(preds)\n",
    "print(labels)\n",
    "print(preds == labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1584/1618 tiles\n",
      "[7 0 7 0 3 0 2 0 9 0]\n",
      "[7 2 1 0 4 1 4 9 5 9]\n",
      "[ True False False  True False False False False False False]\n"
     ]
    }
   ],
   "source": [
    "batch, labels = get_batch(10)\n",
    "\n",
    "results = sim_fp8.predict_batch(batch)\n",
    "preds = np.argmax(results, axis=1)\n",
    "\n",
    "print()\n",
    "print(preds)\n",
    "print(labels)\n",
    "print(preds == labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CompiledAcceleratorConfig(\n",
      "        array_size: 8\n",
      "        activation_type: BF16\n",
      "        weight_type: BF16\n",
      "        multiplier: IEEE 754\n",
      "        accum_addr_width: 12\n",
      "        pipeline: False\n",
      "        name: wb16ab16s8\n",
      "    )\n"
     ]
    }
   ],
   "source": [
    "print(sim_bf16.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True, True, True, True, True, True, True])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_batch(batch_size):\n",
    "    loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    batch, labels = next(iter(loader))\n",
    "    return batch.reshape(batch_size, -1).numpy(), labels\n",
    "\n",
    "\n",
    "batch, labels = get_batch(10)\n",
    "preds == labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(model, torch.nn.Module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7.4215e-09, 7.4465e-12, 4.8801e-07, 6.7055e-06, 3.6637e-14, 3.8199e-10,\n",
       "         9.2704e-15, 1.0000e+00, 1.1350e-09, 4.7730e-08],\n",
       "        [1.3853e-08, 3.4332e-05, 1.0000e+00, 1.1176e-06, 4.6629e-15, 1.6917e-10,\n",
       "         3.8417e-09, 4.4587e-13, 9.1735e-08, 2.2471e-13],\n",
       "        [1.8394e-08, 1.0000e+00, 1.3351e-03, 6.3896e-05, 6.5804e-05, 4.1246e-05,\n",
       "         2.9951e-06, 2.9206e-05, 7.4863e-05, 8.3074e-07],\n",
       "        [1.0000e+00, 1.1539e-11, 3.4051e-09, 7.5033e-11, 2.0140e-08, 3.4226e-08,\n",
       "         2.2352e-07, 2.0373e-10, 4.6020e-10, 3.5912e-06],\n",
       "        [1.5061e-09, 7.0486e-11, 6.4261e-08, 5.4797e-11, 1.0000e+00, 6.1933e-08,\n",
       "         1.7812e-08, 5.1036e-07, 4.2201e-09, 5.3406e-04],\n",
       "        [1.6080e-09, 1.0000e+00, 1.0967e-05, 3.5018e-06, 1.8954e-05, 7.1886e-09,\n",
       "         4.3656e-09, 3.2425e-05, 1.0058e-06, 4.1444e-08],\n",
       "        [7.7716e-14, 2.7753e-07, 3.8445e-06, 1.5497e-06, 1.0000e+00, 1.3828e-05,\n",
       "         2.0838e-08, 5.8711e-06, 8.8120e-04, 1.2207e-04],\n",
       "        [9.5952e-11, 3.7812e-07, 4.5169e-08, 6.4373e-05, 5.3101e-03, 2.9430e-07,\n",
       "         4.0801e-15, 1.6022e-04, 4.6566e-08, 9.9609e-01],\n",
       "        [5.0449e-13, 4.8431e-11, 1.1118e-08, 2.7831e-10, 3.3906e-09, 1.0000e+00,\n",
       "         1.3275e-03, 6.8390e-14, 1.4901e-07, 1.3828e-05],\n",
       "        [1.6712e-11, 1.6556e-12, 2.4556e-10, 2.6077e-07, 2.7161e-03, 5.2387e-09,\n",
       "         7.2831e-14, 2.4128e-04, 1.2070e-06, 9.9609e-01]],\n",
       "       dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(results, dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(results, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4622700768294972"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "CrossEntropyLoss()(torch.tensor(results), labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchvision.datasets.mnist.MNIST"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0.      , 0.      , 3.109375, 0.      ],\n",
      "       [0.      , 9.9375  , 0.      , 0.      ],\n",
      "       [0.      , 0.      , 0.      , 0.      ],\n",
      "       [0.      , 8.0625  , 3.6875  , 3.078125],\n",
      "       [0.      , 7.625   , 0.546875, 0.      ],\n",
      "       [0.      , 0.      , 0.      , 0.      ],\n",
      "       [0.      , 2.609375, 1.15625 , 0.      ],\n",
      "       [0.      , 0.      , 0.      , 0.      ],\n",
      "       [0.      , 9.5625  , 0.      , 0.      ],\n",
      "       [0.      , 7.375   , 0.      , 3.78125 ]]), array([[ 0.      ,  6.8125  ,  6.625   ,  0.      ],\n",
      "       [ 1.9375  ,  0.      ,  0.      ,  4.9375  ],\n",
      "       [ 0.      ,  0.      ,  0.      ,  6.8125  ],\n",
      "       [ 0.      ,  0.      ,  6.9375  ,  0.      ],\n",
      "       [ 0.      ,  5.3125  , 11.8125  ,  0.      ],\n",
      "       [ 0.      ,  1.6875  ,  0.      ,  6.0625  ],\n",
      "       [ 0.      ,  1.078125,  8.5625  ,  0.      ],\n",
      "       [ 0.      ,  3.96875 ,  3.96875 ,  4.0625  ],\n",
      "       [ 0.      ,  0.      , 10.6875  ,  0.      ],\n",
      "       [ 0.      ,  7.6875  ,  5.46875 ,  0.      ]]), array([[ 0.        ,  2.65625   ,  3.5       ,  0.        ],\n",
      "       [ 3.078125  ,  0.        ,  0.        ,  3.875     ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  9.        ],\n",
      "       [ 0.        ,  0.        ,  2.25      ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        , 14.5625    ],\n",
      "       [ 0.        ,  0.        ,  5.34375   ,  0.        ],\n",
      "       [ 1.109375  ,  2.921875  ,  2.03125   ,  0.44140625],\n",
      "       [ 4.875     ,  0.        ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  4.34375   ,  0.        ]]), array([[ 0.        ,  0.        ,  0.        ,  0.        ],\n",
      "       [ 0.        , 12.6875    ,  0.        ,  0.        ],\n",
      "       [ 1.328125  ,  8.4375    ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  5.46875   ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  6.90625   ,  0.        ,  0.84765625],\n",
      "       [ 0.        ,  3.6875    ,  0.        ,  0.        ],\n",
      "       [ 2.375     ,  5.125     ,  0.        ,  1.1484375 ],\n",
      "       [ 0.        ,  2.828125  ,  0.        ,  0.        ],\n",
      "       [ 0.46484375,  0.        ,  0.        ,  0.        ]]), array([[ 0.        ,  0.        ,  0.        ,  0.        ],\n",
      "       [11.375     ,  0.        ,  5.90625   ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  4.625     ,  0.        ,  3.890625  ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  4.1875    ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  0.67578125,  0.        ,  4.59375   ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  5.875     ]]), array([[0.        , 0.        , 3.75      , 0.        ],\n",
      "       [0.39453125, 5.90625   , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [5.375     , 0.51171875, 2.28125   , 0.        ],\n",
      "       [3.703125  , 0.        , 4.28125   , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 1.4453125 , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [2.734375  , 0.        , 1.5703125 , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ]]), array([[ 0.        ,  0.        ,  4.1875    ,  7.15625   ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  4.0625    ,  0.484375  ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  3.84375   ,  4.25      ,  2.875     ],\n",
      "       [ 0.        ,  6.03125   ,  0.16210938,  0.        ],\n",
      "       [ 0.        ,  4.625     , 10.3125    ,  8.5       ],\n",
      "       [ 0.        ,  0.        ,  6.53125   ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  2.703125  ,  0.        ],\n",
      "       [ 1.5703125 ,  0.        , 16.5       ,  9.3125    ]]), array([[ 0.        ,  0.        ,  0.        ,  2.5625    ],\n",
      "       [ 3.328125  ,  0.        ,  0.        ,  6.375     ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  7.53125   ],\n",
      "       [ 0.        ,  0.18066406,  0.        ,  3.296875  ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        , 13.3125    ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  4.4375    ]]), array([[ 0.        ,  4.625     ,  0.3515625 ,  1.109375  ],\n",
      "       [ 0.29882812,  0.        ,  0.        ,  0.        ],\n",
      "       [ 3.546875  ,  0.        ,  4.78125   ,  2.640625  ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
      "       [ 3.890625  ,  2.890625  ,  4.6875    ,  0.        ],\n",
      "       [ 2.375     ,  0.01208496,  4.3125    ,  2.078125  ],\n",
      "       [ 2.609375  ,  0.        ,  8.875     ,  9.5       ],\n",
      "       [ 0.        ,  5.8125    ,  1.1328125 ,  0.        ],\n",
      "       [ 7.0625    ,  0.        , 11.6875    ,  0.        ],\n",
      "       [ 0.        ,  8.375     , 10.6875    ,  0.        ]]), array([[ 0.       ,  1.046875 ,  0.       ,  0.       ],\n",
      "       [ 0.       ,  9.5      ,  0.       ,  0.       ],\n",
      "       [ 5.71875  ,  1.0625   ,  0.       ,  0.       ],\n",
      "       [ 0.       ,  0.       ,  0.       , 11.9375   ],\n",
      "       [ 0.       ,  0.       ,  0.       ,  5.71875  ],\n",
      "       [ 9.25     ,  1.8828125,  0.       ,  0.       ],\n",
      "       [ 0.       ,  0.       ,  0.       ,  0.       ],\n",
      "       [ 3.90625  ,  0.       ,  0.       ,  0.9140625],\n",
      "       [ 0.       ,  4.34375  ,  0.       ,  3.59375  ],\n",
      "       [ 5.75     ,  0.       ,  0.       ,  4.0625   ]]), array([[5.125     , 0.        , 0.        , 0.        ],\n",
      "       [2.0625    , 4.4375    , 0.        , 8.5625    ],\n",
      "       [3.703125  , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.09179688, 0.        , 0.        , 0.        ],\n",
      "       [4.5625    , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.609375  , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [1.796875  , 0.        , 0.        , 0.        ]]), array([[0.        , 9.0625    , 0.        , 0.        ],\n",
      "       [0.66796875, 0.        , 0.        , 0.6171875 ],\n",
      "       [0.        , 2.90625   , 2.234375  , 0.        ],\n",
      "       [4.59375   , 0.        , 0.        , 4.5       ],\n",
      "       [0.        , 1.265625  , 0.        , 0.        ],\n",
      "       [0.        , 2.921875  , 0.35351562, 0.        ],\n",
      "       [0.        , 3.734375  , 0.        , 0.        ],\n",
      "       [1.1796875 , 2.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 4.4375    , 0.        , 0.        ]]), array([[ 0.        ,  0.        ,  0.        ,  8.4375    ],\n",
      "       [ 0.        ,  4.59375   ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
      "       [11.125     ,  0.        ,  0.        ,  3.90625   ],\n",
      "       [ 0.        ,  0.        ,  0.        , 11.6875    ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        , 13.5       ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  4.875     ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  0.70703125]]), array([[ 0.        ,  6.46875   ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  3.90625   ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  0.21289062],\n",
      "       [12.1875    ,  1.703125  ,  0.        ,  0.        ],\n",
      "       [ 2.046875  ,  0.        ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
      "       [ 3.84375   ,  0.        ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  0.        ]]), array([[ 0.        ,  0.        ,  0.        ,  0.        ],\n",
      "       [16.5       ,  0.453125  ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  2.890625  ,  0.        ,  1.5703125 ],\n",
      "       [ 3.109375  ,  0.        ,  0.        ,  0.        ],\n",
      "       [ 0.5625    ,  0.        ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  3.390625  ,  0.        ,  0.13574219],\n",
      "       [ 0.        ,  0.        ,  0.        ,  4.4375    ],\n",
      "       [ 3.90625   ,  0.        ,  0.        ,  4.71875   ],\n",
      "       [ 0.        , 10.6875    ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  6.0625    ]]), array([[0.22558594, 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.5390625 , 2.46875   , 0.        ],\n",
      "       [0.        , 4.625     , 0.        , 0.        ],\n",
      "       [0.40234375, 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 1.9609375 , 7.625     ],\n",
      "       [0.        , 3.125     , 0.        , 0.        ],\n",
      "       [0.        , 3.328125  , 5.59375   , 3.125     ],\n",
      "       [0.        , 0.        , 1.5859375 , 6.65625   ],\n",
      "       [0.        , 0.        , 1.34375   , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 8.625     ]]), array([[ 0.        ,  0.45898438,  0.        ,  0.        ],\n",
      "       [ 0.        ,  1.7890625 ,  0.        ,  9.5       ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  4.5625    ],\n",
      "       [ 0.        , 10.1875    ,  0.        ,  0.        ],\n",
      "       [ 0.        , 10.3125    ,  0.        ,  0.        ],\n",
      "       [ 1.8046875 ,  0.        ,  0.        ,  0.83203125],\n",
      "       [ 0.51171875,  3.046875  ,  3.46875   ,  0.        ],\n",
      "       [ 0.        ,  4.8125    ,  1.21875   ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  2.984375  ,  2.6875    ,  0.        ]]), array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 8.25000000e+00],\n",
      "       [4.25000000e+00, 1.82812500e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       [2.21875000e+00, 9.29687500e-01, 2.20312500e+00, 0.00000000e+00],\n",
      "       [3.70312500e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       [2.78125000e+00, 0.00000000e+00, 0.00000000e+00, 1.32031250e+00],\n",
      "       [6.71386719e-04, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       [4.21875000e+00, 0.00000000e+00, 3.89062500e+00, 7.09375000e+00],\n",
      "       [1.08750000e+01, 3.54687500e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.57421875e-01]]), array([[ 2.328125  ,  0.76171875,  0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  6.28125   ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  6.5625    ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
      "       [ 9.8125    ,  8.1875    ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        , 10.875     ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
      "       [ 1.3359375 , 10.        ,  0.        , 12.75      ],\n",
      "       [12.75      ,  0.        ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  0.        ]]), array([[ 0.        ,  0.        ,  0.        ,  0.9921875 ],\n",
      "       [ 0.        ,  0.        ,  3.203125  ,  0.        ],\n",
      "       [ 0.        ,  5.5       ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  1.2265625 ,  0.94921875],\n",
      "       [ 0.        ,  7.03125   ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  1.34375   ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  1.5234375 ],\n",
      "       [ 0.        ,  2.171875  ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        , 11.3125    ]]), array([[ 0.        ,  0.        ,  2.9375    ,  2.75      ],\n",
      "       [14.125     ,  0.        ,  0.        ,  0.17675781],\n",
      "       [ 6.84375   ,  7.6875    ,  0.        ,  2.875     ],\n",
      "       [ 1.984375  , 13.375     ,  1.25      ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  9.125     ,  0.        ],\n",
      "       [ 6.59375   ,  9.        ,  0.        ,  6.0625    ],\n",
      "       [ 0.        ,  0.        ,  0.06542969,  0.        ],\n",
      "       [ 4.6875    ,  0.68359375,  1.640625  ,  0.        ],\n",
      "       [ 0.        , 10.6875    ,  6.21875   ,  0.35546875],\n",
      "       [ 0.        ,  2.671875  ,  0.8671875 ,  0.        ]]), array([[10.3125    ,  8.625     ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  2.078125  ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  4.625     ,  0.        ,  0.        ],\n",
      "       [ 0.45507812,  0.        ,  0.        ,  0.        ],\n",
      "       [ 0.73828125,  0.        ,  0.        ,  0.        ],\n",
      "       [ 2.828125  ,  0.        ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        , 13.6875    ,  0.        ],\n",
      "       [13.25      ,  0.        ,  0.        ,  0.        ]]), array([[ 0.      ,  0.      ,  0.      ,  4.65625 ],\n",
      "       [ 0.      ,  0.      ,  0.      ,  0.578125],\n",
      "       [ 8.3125  ,  0.      ,  0.      ,  0.      ],\n",
      "       [ 0.      ,  0.      ,  0.      ,  0.      ],\n",
      "       [ 0.      ,  0.      ,  3.328125,  0.      ],\n",
      "       [10.0625  ,  0.      ,  0.      ,  0.      ],\n",
      "       [ 0.      ,  5.8125  ,  8.0625  ,  0.      ],\n",
      "       [ 4.25    ,  8.8125  ,  0.      ,  0.      ],\n",
      "       [ 0.      ,  0.      ,  8.25    ,  0.      ],\n",
      "       [ 5.625   ,  7.78125 ,  2.796875,  0.      ]]), array([[10.875     ,  0.        ,  0.37109375,  3.8125    ],\n",
      "       [ 0.        ,  0.        ,  1.109375  ,  9.25      ],\n",
      "       [ 9.25      ,  0.        ,  1.0859375 ,  1.65625   ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  1.390625  ],\n",
      "       [ 0.        ,  0.        ,  3.125     ,  0.        ],\n",
      "       [12.4375    ,  0.        ,  0.        ,  3.484375  ],\n",
      "       [ 0.71484375,  0.        , 11.125     ,  1.0234375 ],\n",
      "       [ 0.        ,  0.        ,  6.15625   ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  7.        ,  6.78125   ],\n",
      "       [11.1875    ,  0.        ,  9.25      ,  0.        ]]), array([[ 0.      ,  2.484375,  0.      , 11.375   ],\n",
      "       [ 0.      ,  0.      ,  0.      ,  0.      ],\n",
      "       [ 4.375   ,  0.      ,  0.      ,  0.      ],\n",
      "       [ 0.      ,  0.      ,  0.      ,  4.03125 ],\n",
      "       [ 0.      ,  0.      ,  0.      ,  0.      ],\n",
      "       [ 2.0625  ,  0.      ,  0.      ,  0.      ],\n",
      "       [ 0.      ,  6.21875 ,  0.      ,  0.      ],\n",
      "       [ 0.      ,  0.      ,  0.      ,  0.      ],\n",
      "       [ 0.      ,  0.      ,  0.      ,  0.      ],\n",
      "       [ 0.      ,  5.1875  ,  0.      ,  8.4375  ]]), array([[ 0.        ,  0.        ,  4.1875    ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  8.75      ],\n",
      "       [ 2.34375   ,  0.        ,  7.        ,  2.40625   ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
      "       [ 4.75      ,  0.        ,  0.        ,  0.        ],\n",
      "       [ 0.97265625,  0.        , 10.0625    ,  2.890625  ],\n",
      "       [ 4.09375   ,  0.        ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  2.484375  ,  0.        ,  0.        ],\n",
      "       [18.875     ,  0.        ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  0.        ]]), array([[1.1015625 , 7.03125   , 0.        , 1.515625  ],\n",
      "       [0.        , 0.        , 0.        , 4.71875   ],\n",
      "       [1.7109375 , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [2.59375   , 0.        , 8.4375    , 0.        ],\n",
      "       [1.96875   , 0.        , 0.        , 0.        ],\n",
      "       [6.4375    , 0.        , 0.        , 0.        ],\n",
      "       [1.7421875 , 5.78125   , 5.75      , 0.        ],\n",
      "       [0.        , 0.        , 5.125     , 0.        ],\n",
      "       [0.44335938, 0.        , 0.        , 0.        ]]), array([[0.        , 0.765625  , 0.        , 7.59375   ],\n",
      "       [4.59375   , 0.        , 0.24609375, 0.        ],\n",
      "       [1.4453125 , 0.        , 0.        , 1.1484375 ],\n",
      "       [0.        , 0.        , 0.        , 1.0390625 ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [2.0625    , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 6.15625   ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [1.3515625 , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 2.921875  , 0.        , 0.        ]]), array([[ 2.28125   ,  0.        ,  4.53125   ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  0.18359375],\n",
      "       [ 6.90625   ,  0.        ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  8.9375    ,  1.46875   ],\n",
      "       [ 0.        ,  0.        ,  3.796875  ,  0.        ],\n",
      "       [ 7.6875    ,  0.        ,  0.        ,  0.        ],\n",
      "       [ 4.8125    ,  0.        ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.5234375 ,  0.        ],\n",
      "       [ 1.859375  ,  2.09375   ,  0.        ,  0.        ],\n",
      "       [ 3.5625    ,  0.        , 11.125     ,  0.        ]]), array([[ 0.        , 12.125     ,  1.1015625 ,  0.        ],\n",
      "       [ 3.03125   ,  0.        ,  0.        ,  2.53125   ],\n",
      "       [ 0.        ,  0.        ,  1.1171875 ,  0.        ],\n",
      "       [ 1.5       ,  6.09375   ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  4.96875   ],\n",
      "       [ 0.        ,  0.        ,  1.2421875 ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  4.25      ,  0.60546875],\n",
      "       [ 0.        , 10.4375    ,  0.0234375 ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
      "       [ 0.        , 10.25      ,  0.71484375,  0.        ]]), array([[ 0.       ,  0.       ,  0.       ,  0.       ],\n",
      "       [ 2.0625   , 11.375    , 15.1875   ,  8.0625   ],\n",
      "       [ 0.       ,  0.       ,  2.421875 ,  2.40625  ],\n",
      "       [ 0.       ,  6.90625  , 24.       ,  0.       ],\n",
      "       [ 0.       ,  0.7734375,  0.       ,  0.       ],\n",
      "       [ 0.       ,  0.       ,  1.4765625,  1.046875 ],\n",
      "       [ 0.       ,  0.       ,  0.       ,  0.       ],\n",
      "       [ 4.03125  ,  0.       ,  0.       ,  0.       ],\n",
      "       [ 0.       , 16.125    ,  3.671875 ,  2.59375  ],\n",
      "       [ 0.       ,  0.       ,  0.       ,  0.       ]]), array([[3.046875, 0.      , 0.      , 8.375   ],\n",
      "       [0.      , 1.      , 0.      , 0.      ],\n",
      "       [2.      , 0.      , 0.      , 0.      ],\n",
      "       [0.      , 0.      , 0.      , 5.1875  ],\n",
      "       [0.      , 0.      , 0.      , 0.      ],\n",
      "       [3.09375 , 0.      , 0.      , 0.      ],\n",
      "       [0.      , 0.      , 0.      , 0.      ],\n",
      "       [0.      , 0.      , 0.      , 5.15625 ],\n",
      "       [0.      , 0.      , 0.      , 0.      ],\n",
      "       [0.      , 0.      , 0.      , 6.625   ]])]\n",
      "\n",
      "Hidden layer output shape: (10, 128)\n",
      "\n",
      "After second bias trick:\n",
      "W2_aug shape: (10, 129)\n",
      "h_aug shape: (10, 129)\n",
      "Completed 6304/6403 tiles\n",
      "Number of output chunks: 3\n",
      "Chunk 0 shape: (10, 4)\n",
      "Chunk 1 shape: (10, 4)\n",
      "Chunk 2 shape: (10, 4)\n",
      "\n",
      "Final output shape: (10, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.001462270076829497, 100.0)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation function\n",
    "def evaluate(\n",
    "    sim: CompiledAcceleratorSimulator,\n",
    "    model: MLP,\n",
    "    dataset,\n",
    "    batch_size,\n",
    "    criterion=CrossEntropyLoss(),\n",
    "):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0.0\n",
    "    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    for batch, labels in data_loader:\n",
    "        batch = batch.reshape(batch_size, -1).numpy()\n",
    "        outputs = sim.predict_batch(model, batch)\n",
    "        loss = criterion(torch.tensor(outputs), labels)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Get predictions from the maximum value\n",
    "        predicted = np.argmax(outputs, axis=1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        break\n",
    "    avg_loss = running_loss / len(data_loader)\n",
    "    accuracy = 100.0 * correct / total\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "\n",
    "evaluate(sim_bf16, model, test_dataset, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hardware_accelerators.simulation.matrix_utils import bias_trick\n",
    "\n",
    "\n",
    "weights_1 = model.fc1.weight.numpy(force=True)\n",
    "bias_1 = model.fc1.bias.numpy(force=True)\n",
    "weights_2 = model.fc2.weight.numpy(force=True)\n",
    "bias_2 = model.fc2.bias.numpy(force=True)\n",
    "\n",
    "# Apply the bias trick\n",
    "W1_aug = bias_trick(weights_1, bias_1)\n",
    "W2_aug = bias_trick(weights_2, bias_2)\n",
    "\n",
    "W1_aug.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000.0"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10000 / 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compiling all configurations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterator, Type, List, Callable\n",
    "from itertools import product\n",
    "\n",
    "from hardware_accelerators.dtypes import *\n",
    "\n",
    "\n",
    "def generate_accelerator_configs(\n",
    "    array_size: int = 16,\n",
    "    dtypes: List[Type[BaseFloat]] = None,\n",
    "    multipliers: List[Callable] = None,\n",
    ") -> Iterator[CompiledAcceleratorConfig]:\n",
    "    \"\"\"\n",
    "    Generate all valid CompiledAcceleratorConfig combinations.\n",
    "\n",
    "    Args:\n",
    "        array_size: Size of the systolic array\n",
    "        dtypes: List of data types to consider. Defaults to [Float8, BF16, FP16, FP32]\n",
    "        multipliers: List of multiplier functions. Defaults to [float_multiplier, lmul]\n",
    "\n",
    "    Yields:\n",
    "        Valid CompiledAcceleratorConfig objects\n",
    "\n",
    "    Restrictions:\n",
    "        1. The activation_type must be greater than or equal to the weight_type in terms of bitwidth.\n",
    "        2. 16-bit float types (BF16, FP16) should not be combined with each other.\n",
    "           They should only pair with themselves or with FP32.\n",
    "    \"\"\"\n",
    "    if dtypes is None:\n",
    "        dtypes = [Float8, BF16, Float16, Float32]\n",
    "\n",
    "    if multipliers is None:\n",
    "        multipliers = [float_multiplier, lmul_fast]\n",
    "\n",
    "    # Sort dtypes by bitwidth for easier comparison\n",
    "    dtype_bitwidths = {dtype: dtype.bitwidth() for dtype in dtypes}\n",
    "    sorted_dtypes = sorted(dtypes, key=lambda d: dtype_bitwidths[d])\n",
    "\n",
    "    # Identify 16-bit float types\n",
    "    bit16_float_types = [dtype for dtype in dtypes if dtype_bitwidths[dtype] == 16]\n",
    "\n",
    "    # Generate all combinations\n",
    "    for multiplier in multipliers:\n",
    "        for weight_type in sorted_dtypes:\n",
    "            # Find valid activation types based on bitwidth\n",
    "            valid_activation_types = [\n",
    "                dtype\n",
    "                for dtype in sorted_dtypes\n",
    "                if dtype_bitwidths[dtype] >= dtype_bitwidths[weight_type]\n",
    "            ]\n",
    "\n",
    "            for activation_type in valid_activation_types:\n",
    "                # Skip invalid combinations of 16-bit float types\n",
    "                if (\n",
    "                    weight_type in bit16_float_types\n",
    "                    and activation_type in bit16_float_types\n",
    "                    and weight_type != activation_type\n",
    "                ):\n",
    "                    continue\n",
    "\n",
    "                yield CompiledAcceleratorConfig(\n",
    "                    array_size=array_size,\n",
    "                    activation_type=activation_type,\n",
    "                    weight_type=weight_type,\n",
    "                    multiplier=multiplier,\n",
    "                )\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "def print_all_configs():\n",
    "    for i, config in enumerate(generate_accelerator_configs()):\n",
    "        print(f\"Config {i+1}:\")\n",
    "        print(f\"  Array Size: {config.array_size}\")\n",
    "        print(f\"  Activation Type: {config.activation_type.__name__}\")\n",
    "        print(f\"  Weight Type: {config.weight_type.__name__}\")\n",
    "        print(f\"  Multiplier: {config.multiplier.__name__}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config 1:\n",
      "  Array Size: 16\n",
      "  Activation Type: Float8\n",
      "  Weight Type: Float8\n",
      "  Multiplier: float_multiplier\n",
      "\n",
      "Config 2:\n",
      "  Array Size: 16\n",
      "  Activation Type: BF16\n",
      "  Weight Type: Float8\n",
      "  Multiplier: float_multiplier\n",
      "\n",
      "Config 3:\n",
      "  Array Size: 16\n",
      "  Activation Type: Float16\n",
      "  Weight Type: Float8\n",
      "  Multiplier: float_multiplier\n",
      "\n",
      "Config 4:\n",
      "  Array Size: 16\n",
      "  Activation Type: Float32\n",
      "  Weight Type: Float8\n",
      "  Multiplier: float_multiplier\n",
      "\n",
      "Config 5:\n",
      "  Array Size: 16\n",
      "  Activation Type: BF16\n",
      "  Weight Type: BF16\n",
      "  Multiplier: float_multiplier\n",
      "\n",
      "Config 6:\n",
      "  Array Size: 16\n",
      "  Activation Type: Float32\n",
      "  Weight Type: BF16\n",
      "  Multiplier: float_multiplier\n",
      "\n",
      "Config 7:\n",
      "  Array Size: 16\n",
      "  Activation Type: Float16\n",
      "  Weight Type: Float16\n",
      "  Multiplier: float_multiplier\n",
      "\n",
      "Config 8:\n",
      "  Array Size: 16\n",
      "  Activation Type: Float32\n",
      "  Weight Type: Float16\n",
      "  Multiplier: float_multiplier\n",
      "\n",
      "Config 9:\n",
      "  Array Size: 16\n",
      "  Activation Type: Float32\n",
      "  Weight Type: Float32\n",
      "  Multiplier: float_multiplier\n",
      "\n",
      "Config 10:\n",
      "  Array Size: 16\n",
      "  Activation Type: Float8\n",
      "  Weight Type: Float8\n",
      "  Multiplier: lmul_fast\n",
      "\n",
      "Config 11:\n",
      "  Array Size: 16\n",
      "  Activation Type: BF16\n",
      "  Weight Type: Float8\n",
      "  Multiplier: lmul_fast\n",
      "\n",
      "Config 12:\n",
      "  Array Size: 16\n",
      "  Activation Type: Float16\n",
      "  Weight Type: Float8\n",
      "  Multiplier: lmul_fast\n",
      "\n",
      "Config 13:\n",
      "  Array Size: 16\n",
      "  Activation Type: Float32\n",
      "  Weight Type: Float8\n",
      "  Multiplier: lmul_fast\n",
      "\n",
      "Config 14:\n",
      "  Array Size: 16\n",
      "  Activation Type: BF16\n",
      "  Weight Type: BF16\n",
      "  Multiplier: lmul_fast\n",
      "\n",
      "Config 15:\n",
      "  Array Size: 16\n",
      "  Activation Type: Float32\n",
      "  Weight Type: BF16\n",
      "  Multiplier: lmul_fast\n",
      "\n",
      "Config 16:\n",
      "  Array Size: 16\n",
      "  Activation Type: Float16\n",
      "  Weight Type: Float16\n",
      "  Multiplier: lmul_fast\n",
      "\n",
      "Config 17:\n",
      "  Array Size: 16\n",
      "  Activation Type: Float32\n",
      "  Weight Type: Float16\n",
      "  Multiplier: lmul_fast\n",
      "\n",
      "Config 18:\n",
      "  Array Size: 16\n",
      "  Activation Type: Float32\n",
      "  Weight Type: Float32\n",
      "  Multiplier: lmul_fast\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_all_configs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsc180",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
