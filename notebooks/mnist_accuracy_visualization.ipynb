 {
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Evaluation Results Visualization\n",
    "\n",
    "This notebook visualizes the accuracy and performance metrics from the MNIST evaluation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# Set the style for the plots\n",
    "plt.style.use('ggplot')\n",
    "sns.set_palette(\"colorblind\")\n",
    "plt.rcParams['figure.figsize'] = [12, 8]\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the MNIST Evaluation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load the data from the CSV file\n",
    "data_path = '../results/mnist_eval.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Display the data\n",
    "print(f\"Loaded {len(df)} configurations from {data_path}\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create a bar chart for accuracy\n",
    "plt.figure(figsize=(14, 8))\n",
    "ax = sns.barplot(x='config', y='accuracy', data=df, palette='viridis')\n",
    "\n",
    "# Add data labels on top of each bar\n",
    "for i, v in enumerate(df['accuracy']):\n",
    "    ax.text(i, v + 0.5, f\"{v:.2f}%\", ha='center', fontweight='bold')\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('MNIST Accuracy by Configuration', fontsize=18, pad=20)\n",
    "plt.xlabel('Configuration', fontsize=14)\n",
    "plt.ylabel('Accuracy (%)', fontsize=14)\n",
    "plt.ylim(0, 105)  # Set y-axis limit to accommodate the labels\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Add a horizontal line for reference at 95% accuracy\n",
    "plt.axhline(y=95, color='r', linestyle='--', alpha=0.5, label='95% Threshold')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined Visualization: Accuracy and Configuration Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create a figure with subplots\n",
    "fig, ax = plt.subplots(figsize=(16, 10))\n",
    "\n",
    "# Create a colormap based on weight and activation types\n",
    "color_map = {\n",
    "    ('Float8', 'Float8'): 'tab:blue',\n",
    "    ('BF16', 'BF16'): 'tab:orange',\n",
    "    ('Float8', 'BF16'): 'tab:green'\n",
    "}\n",
    "\n",
    "# Get colors based on weight and activation types\n",
    "colors = [color_map.get((w, a), 'tab:gray') for w, a in zip(df['weight_type'], df['activation_type'])]\n",
    "\n",
    "# Create the bar chart\n",
    "bars = ax.bar(df['config'], df['accuracy'], color=colors)\n",
    "\n",
    "# Add data labels\n",
    "for bar, acc in zip(bars, df['accuracy']):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
    "            f'{acc:.2f}%', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Customize the plot\n",
    "ax.set_title('MNIST Accuracy by Hardware Configuration', fontsize=20, pad=20)\n",
    "ax.set_xlabel('Configuration', fontsize=16)\n",
    "ax.set_ylabel('Accuracy (%)', fontsize=16)\n",
    "ax.set_ylim(0, 105)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "# Add a grid\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Create a custom legend\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [Patch(facecolor=color, label=f'{w}-{a}') \n",
    "                   for (w, a), color in color_map.items()]\n",
    "ax.legend(handles=legend_elements, title='Weight-Activation Types', \n",
    "          loc='lower right', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Metrics Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create a figure with multiple subplots\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 12))\n",
    "\n",
    "# Plot 1: Total execution time\n",
    "sns.barplot(x='config', y='total_time', data=df, ax=axes[0], palette='Blues_d')\n",
    "axes[0].set_title('Total Execution Time by Configuration', fontsize=16)\n",
    "axes[0].set_xlabel('')\n",
    "axes[0].set_ylabel('Time (ms)', fontsize=14)\n",
    "axes[0].set_xticklabels(axes[0].get_xticklabels(), rotation=45, ha='right')\n",
    "axes[0].grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Add data labels\n",
    "for i, v in enumerate(df['total_time']):\n",
    "    if not pd.isna(v):\n",
    "        axes[0].text(i, v + 100, f\"{v:.1f}\", ha='center')\n",
    "\n",
    "# Plot 2: Samples per second (throughput)\n",
    "sns.barplot(x='config', y='samples_per_second', data=df, ax=axes[1], palette='Greens_d')\n",
    "axes[1].set_title('Throughput (Samples per Second) by Configuration', fontsize=16)\n",
    "axes[1].set_xlabel('Configuration', fontsize=14)\n",
    "axes[1].set_ylabel('Samples/Second', fontsize=14)\n",
    "axes[1].set_xticklabels(axes[1].get_xticklabels(), rotation=45, ha='right')\n",
    "axes[1].grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Add data labels\n",
    "for i, v in enumerate(df['samples_per_second']):\n",
    "    if not pd.isna(v):\n",
    "        axes[1].text(i, v + 0.1, f\"{v:.2f}\", ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy vs. Performance Trade-off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create a scatter plot to visualize the trade-off between accuracy and performance\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Create a scatter plot with custom colors based on configuration\n",
    "scatter = plt.scatter(df['total_time'], df['accuracy'], \n",
    "                      c=[plt.cm.viridis(i/len(df)) for i in range(len(df))],\n",
    "                      s=100, alpha=0.7)\n",
    "\n",
    "# Add labels for each point\n",
    "for i, config in enumerate(df['config']):\n",
    "    plt.annotate(config, \n",
    "                 (df['total_time'].iloc[i], df['accuracy'].iloc[i]),\n",
    "                 xytext=(10, 5), textcoords='offset points',\n",
    "                 fontsize=10, fontweight='bold')\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Accuracy vs. Execution Time Trade-off', fontsize=18)\n",
    "plt.xlabel('Total Execution Time (ms)', fontsize=14)\n",
    "plt.ylabel('Accuracy (%)', fontsize=14)\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Add a colorbar legend\n",
    "plt.colorbar(plt.cm.ScalarMappable(cmap='viridis'), \n",
    "             label='Configuration Index')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create a summary table\n",
    "summary_df = df[['config', 'weight_type', 'activation_type', 'multiplier', 'accuracy', 'total_time', 'samples_per_second']].copy()\n",
    "\n",
    "# Sort by accuracy (descending)\n",
    "summary_df = summary_df.sort_values('accuracy', ascending=False)\n",
    "\n",
    "# Display the summary\n",
    "summary_df.style.background_gradient(subset=['accuracy'], cmap='Greens')\\\n",
    "    .background_gradient(subset=['total_time'], cmap='Reds_r')\\\n",
    "    .background_gradient(subset=['samples_per_second'], cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Findings\n",
    "\n",
    "Based on the visualizations above, we can draw the following conclusions:\n",
    "\n",
    "1. **Accuracy Performance**: The BF16 configurations (wb16ab16-8x8 and w8ab16-8x8) achieve significantly higher accuracy (>97%) compared to the Float8 configuration (w8a8-8x8) which only achieves around 9.59% accuracy.\n",
    "\n",
    "2. **Execution Time**: There are notable differences in execution time across configurations, with potential trade-offs between accuracy and speed.\n",
    "\n",
    "3. **Throughput**: The samples per second metric shows how efficiently each configuration processes the data, with some configurations showing better throughput despite longer total execution times.\n",
    "\n",
    "4. **Weight-Activation Type Impact**: The combination of weight and activation types significantly affects both accuracy and performance, with BF16 types generally providing better accuracy.\n",
    "\n",
    "5. **Multiplier Impact**: The choice of multiplier implementation (float_multiplier vs. lmul_fast) affects the performance characteristics while maintaining similar accuracy levels.\n",
    "\n",
    "These insights can guide hardware accelerator design decisions based on specific requirements for accuracy vs. performance trade-offs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}